{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate Azure ML SDK installation and get version number for debugging purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check core SDK version number\n",
    "import azureml.core\n",
    "print(\"SDK version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diagnostics\n",
    "Opt-in diagnostics for better experience, quality, and security of future releases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.telemetry import set_diagnostics_collection\n",
    "set_diagnostics_collection(send_diagnostics = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Workspace\n",
    "Initialize a workspace object from persisted configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Workspace\n",
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print(\"Resource group: \", ws.resource_group)\n",
    "print(\"Location: \", ws.location)\n",
    "print(\"Workspace name: \", ws.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set experiment name and create project\n",
    "Choose a name for your run history container in the workspace, and create a folder for the project.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path, makedirs\n",
    "experiment_name = 'tensorboard-demo'\n",
    "\n",
    "# experiment folder\n",
    "exp_dir = '../projects/' + experiment_name\n",
    "\n",
    "if not path.exists(exp_dir):\n",
    "    makedirs(exp_dir)\n",
    "\n",
    "# runs we started in this session, for the finale\n",
    "runs = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Tensorflow TensorBoard demo code\n",
    "Tensorflow's repository has an MNIST demo with extensive TensorBoard instrumentation. We'll use it here for our purposes.\n",
    "Note that we don't need to make any code changes at all - the code works without modification from the Tensorflow repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import tempfile\n",
    "tf_code = requests.get(\"https://raw.githubusercontent.com/tensorflow/tensorflow/r1.8/tensorflow/examples/tutorials/mnist/mnist_with_summaries.py\")\n",
    "with open(os.path.join(exp_dir, \"mnist_with_summaries.py\"), \"w\") as file:\n",
    "    file.write(tf_code.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure and run locally\n",
    "We'll start by running this locally. While it might not initially seem that useful to use this for a local run - why not just run TB against the files generated locally? - even in this case there is some value to using this feature. Your local run will be registered in the run history, and your TensorBoard logs will be uploaded to the artifact store associated with this run. Later, you'll be able to restore the logs from any run, regardless of where it happened.\n",
    "\n",
    "**Note** that for this run, you will need to install TensorFlow on your local machine by yourself. Further, the TensorBoard module (that is, the one included with TensorFlow) must be accessible to this notebook's kernel, as the local machine is what runs TensorBoard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.runconfig import RunConfiguration\n",
    "\n",
    "# Create a run configuration.\n",
    "run_config = RunConfiguration()\n",
    "run_config.environment.python.user_managed_dependencies = True\n",
    "\n",
    "# You can choose a specific Python environment by pointing to a Python path \n",
    "#run_config.environment.python.interpreter_path = '/home/ninghai/miniconda3/envs/sdk2/bin/python'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment, Run\n",
    "from azureml.core.script_run_config import ScriptRunConfig\n",
    "import tensorflow as tf\n",
    "\n",
    "logs_dir = os.path.join(os.curdir, \"logs\")\n",
    "data_dir = os.path.abspath(os.path.join(os.curdir, \"../MNIST_data\"))\n",
    "\n",
    "if not path.exists(data_dir):\n",
    "    makedirs(data_dir)\n",
    "\n",
    "os.environ[\"TEST_TMPDIR\"] = data_dir\n",
    "\n",
    "# Writing logs to ./logs results in their being uploaded to Artifact Service,\n",
    "# and thus, made accessible to our TensorBoard instance.\n",
    "arguments_list = [\"--log_dir\", logs_dir, \"--data_dir\", data_dir]\n",
    "\n",
    "# Create an experiment\n",
    "exp = Experiment(ws, experiment_name)\n",
    "\n",
    "# If you would like the run to go for longer, add --max_steps 5000 to the arguments list:\n",
    "# arguments_list += [\"--max_steps\", \"5000\"]\n",
    "\n",
    "script = ScriptRunConfig(exp_dir,\n",
    "                         script=\"mnist_with_summaries.py\",\n",
    "                         run_config=run_config,\n",
    "                         arguments=arguments_list)\n",
    "\n",
    "run = exp.submit(script)\n",
    "runs.append(run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.widgets import RunDetails\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start TensorBoard\n",
    "Now, while the run is in progress, we just need to start TensorBoard with the run as its target, and it will begin streaming logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.contrib.tensorboard import Tensorboard\n",
    "\n",
    "# The TensorBoard constructor takes an array of runs, so be sure and pass it in as a single-element array here\n",
    "tb = Tensorboard([run])\n",
    "\n",
    "# If successful, start() returns a string with the URI of the instance.\n",
    "tb.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop TensorBoard\n",
    "When you're done, make sure to call the stop() method of the TensorBoard object, or it will stay running even after your job completes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Once more, with a Batch AI cluster\n",
    "Just to prove we can, let's create a Batch AI cluster using MLC, and run our demo there, as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.compute import BatchAiCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "compute_target_name = 'myazbai'\n",
    "\n",
    "try:\n",
    "    batch_ai_compute = BatchAiCompute(workspace=ws, name=compute_target_name)\n",
    "    print('found existing:', batch_ai_compute.name)\n",
    "except ComputeTargetException:\n",
    "    print('creating new.')\n",
    "    batch_ai_config = BatchAiCompute.provisioning_configuration(\n",
    "        vm_size=\"Standard_NC6\",\n",
    "        vm_priority=\"dedicated\",\n",
    "        autoscale_enabled = True,\n",
    "        cluster_min_nodes = 0,\n",
    "        cluster_max_nodes = 4\n",
    "    )\n",
    "    batch_ai_compute = BatchAiCompute.create(\n",
    "        ws, \n",
    "        name=compute_target_name, \n",
    "        provisioning_configuration=batch_ai_config\n",
    "    )\n",
    "    batch_ai_compute.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit run using TensorFlow estimator\n",
    "Again, we can use the TensorFlow estimator and everything is set up automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.dnn import TensorFlow\n",
    "\n",
    "script_params = {\n",
    "    \"--log_dir\": \"./logs\"\n",
    "}\n",
    "\n",
    "tf_estimator = TensorFlow(\n",
    "    source_directory=exp_dir,\n",
    "    compute_target=batch_ai_compute,\n",
    "    entry_script='mnist_with_summaries.py',\n",
    "    script_params=script_params\n",
    ")\n",
    "\n",
    "run = exp.submit(tf_estimator)\n",
    "\n",
    "runs.append(run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from azureml.train.widgets import RunDetails\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start TensorBoard with this run\n",
    "Once more..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.contrib.tensorboard import Tensorboard\n",
    "\n",
    "# The TensorBoard constructor takes an array of runs, so be sure and pass it in as a single-element array here\n",
    "tb = Tensorboard([run])\n",
    "\n",
    "# If successful, start() returns a string with the URI of the instance.\n",
    "tb.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop TensorBoard\n",
    "When you're done, make sure to call the stop() method of the TensorBoard object, or it will stay running even after your job completes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finale\n",
    "If you've paid close attention, you'll have noticed that we've been saving the run objects in an array as we went along. We can start a TensorBoard instance that combines all of these run objects into a single process. This way, you can compare historical runs. You can even do this with live runs; if you made some of those previous runs longer via the --max_steps parameter, they might still be running, and you'll see them live in this instance as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.contrib.tensorboard import Tensorboard\n",
    "\n",
    "# The TensorBoard constructor takes an array of runs...\n",
    "# and it turns out that we have been building one of those all along.\n",
    "tb = Tensorboard(runs)\n",
    "\n",
    "# If successful, start() returns a string with the URI of the instance.\n",
    "tb.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop TensorBoard\n",
    "As you might already know, make sure to call the stop() method of the TensorBoard object, or it will stay running (until you kill the kernel associated with this notebook, at least)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
