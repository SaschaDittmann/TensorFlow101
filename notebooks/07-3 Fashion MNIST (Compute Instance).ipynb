{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fashion MNIST\n",
    "\n",
    "## Validate Azure ML SDK installation and get version number for debugging purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check core SDK version number\n",
    "import azureml.core\n",
    "print(\"SDK version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Workspace\n",
    "Initialize a workspace object from persisted configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Workspace\n",
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print(\"Resource group: \", ws.resource_group)\n",
    "print(\"Location: \", ws.location)\n",
    "print(\"Workspace name: \", ws.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a project directory\n",
    "Create a directory that will contain all the necessary code from your local machine that you will need access to on the remote resource. This includes the training script, and any additional files your training script depends on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "project_folder = '../projects/fashion_mnist_remote_vm'\n",
    "os.makedirs(project_folder, exist_ok=True)\n",
    "\n",
    "shutil.copy('./scripts/train_Fashion_MNIST.py', project_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create An Experiment\n",
    "**Experiment** is a logical container in an Azure ML Workspace. It hosts run records which can include run metrics and output artifacts from your experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "experiment_name = 'fashion-mnist'\n",
    "experiment = Experiment(workspace = ws, name = experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Azure ML Compute Instance\n",
    "**Note:** Use a compute instance as your fully configured and managed development environment in the cloud. For development and testing, you can also use the instance as a training compute target or for an inference target. A compute instance can run multiple jobs in parallel and has a job queue. As a development environment, a compute instance cannot be shared with other users in your workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.compute import ComputeTarget, ComputeInstance\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "# Choose a name for your instance\n",
    "# Compute instance name should be unique across the azure region\n",
    "compute_name = \"ci{}\".format(ws._workspace_id)[:10]\n",
    "\n",
    "# Verify that instance does not exist already\n",
    "try:\n",
    "    instance = ComputeInstance(workspace=ws, name=compute_name)\n",
    "    print('Found existing instance, use it.')\n",
    "except ComputeTargetException:\n",
    "    compute_config = ComputeInstance.provisioning_configuration(\n",
    "        vm_size='STANDARD_D3_V2',\n",
    "        ssh_public_access=False,\n",
    "        # vnet_resourcegroup_name='<my-resource-group>',\n",
    "        # vnet_name='<my-vnet-name>',\n",
    "        # subnet_name='default',\n",
    "        # admin_user_ssh_public_key='<my-sshkey>'\n",
    "    )\n",
    "    instance = ComputeInstance.create(ws, compute_name, compute_config)\n",
    "    instance.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start ComputeInstance target, if necessary\n",
    "if instance.get_status().state==\"Stopped\":\n",
    "    instance.start(wait_for_completion=True, show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Training Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from azureml.core.environment import Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "myenv = Environment(name=\"mytfenv\")\n",
    "\n",
    "# Adds dependencies to PythonSection of myenv\n",
    "conda_dep = CondaDependencies()\n",
    "conda_dep.add_conda_package(\"matplotlib=3.3.3\")\n",
    "conda_dep.add_pip_package(\"tensorflow-gpu==2.4.1\")\n",
    "myenv.python.conda_dependencies=conda_dep\n",
    "\n",
    "myenv.register(workspace=ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL: Pre-Build Docker Image for Training\n",
    "from azureml.core import Image\n",
    "build = myenv.build(workspace=ws)\n",
    "build.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload Data to Azure\n",
    "1. Download the [Fashion MNIST Dataset](https://github.com/zalandoresearch/fashion-mnist) from GitHub\n",
    "1. Upload the files to the Azure ML Default DataStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "\n",
    "data_folder = '../data/fashion_mnist'\n",
    "os.makedirs(data_folder, exist_ok = True)\n",
    "urllib.request.urlretrieve('https://github.com/zalandoresearch/fashion-mnist/raw/master/data/fashion/train-images-idx3-ubyte.gz', filename=os.path.join(data_folder, \"train-images.gz\"))\n",
    "urllib.request.urlretrieve('https://github.com/zalandoresearch/fashion-mnist/raw/master/data/fashion/train-labels-idx1-ubyte.gz', filename=os.path.join(data_folder, \"train-labels.gz\"))\n",
    "urllib.request.urlretrieve('https://github.com/zalandoresearch/fashion-mnist/raw/master/data/fashion/t10k-images-idx3-ubyte.gz', filename=os.path.join(data_folder, \"test-images.gz\"))\n",
    "urllib.request.urlretrieve('https://github.com/zalandoresearch/fashion-mnist/raw/master/data/fashion/t10k-labels-idx1-ubyte.gz', filename=os.path.join(data_folder, \"test-labels.gz\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ws.get_default_datastore()\n",
    "\n",
    "print(\"Datastore details:\")\n",
    "print(\"Type:\", ds.datastore_type)\n",
    "print(\"Storage Account:\", ds.account_name)\n",
    "print(\"Blob Container Name:\", ds.container_name)\n",
    "\n",
    "ds.upload(src_dir=data_folder, target_path='fashion_mnist', overwrite=True, show_progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit the Experiment\n",
    "Finally, run the training job on the DSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import ScriptRunConfig\n",
    "\n",
    "script_params = [ '--data-folder', str(ds.as_mount()), '--batch-size', 128, '--epochs', 24]\n",
    "\n",
    "runconfig = ScriptRunConfig(source_directory=project_folder,\n",
    "                            compute_target=instance,\n",
    "                            environment=myenv,\n",
    "                            script='train_Fashion_MNIST.py',\n",
    "                            arguments=script_params)\n",
    "\n",
    "runconfig.run_config.data_references = {\n",
    "    ds.as_mount().data_reference_name: ds.as_mount().to_config()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = experiment.submit(runconfig)\n",
    "run.tag(\"Description\",\"Compute Instance trained Fashion MNIST model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all metris logged in the run\n",
    "run.get_metrics()\n",
    "metrics = run.get_metrics()\n",
    "\n",
    "import numpy as np\n",
    "print('loss is {0:.2f}, and accuracy is {1:0.2f}'.format(\n",
    "    metrics['loss'], \n",
    "    metrics['accuracy']\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot data to see relationships in training and validation data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "epoch_list = list(range(1, len(metrics['Training Accuracy']) + 1))  # values for x axis [1, 2, ..., # of epochs]\n",
    "plt.plot(epoch_list, metrics['Training Accuracy'], epoch_list, metrics['Validation Accuracy'])\n",
    "plt.legend(('Training Accuracy', 'Validation Accuracy'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show all the files stored within the run record\n",
    "run.get_file_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "outputs_path = os.path.join(project_folder, \"outputs\")\n",
    "os.makedirs(outputs_path, exist_ok=True)\n",
    "\n",
    "for filename in run.get_file_names():\n",
    "    if filename.startswith('outputs'):\n",
    "        path = os.path.join(project_folder, filename)\n",
    "        print(\"Downloading \" + filename)\n",
    "        run.download_file(filename, output_file_path=outputs_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up compute resource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instance.stop(wait_for_completion=True, show_output=True)\n",
    "instance.delete(wait_for_completion=True, show_output=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
