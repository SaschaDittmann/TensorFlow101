{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate Azure ML SDK installation and get version number for debugging purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check core SDK version number\n",
    "import azureml.core\n",
    "print(\"SDK version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diagnostics\n",
    "Opt-in diagnostics for better experience, quality, and security of future releases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.telemetry import set_diagnostics_collection\n",
    "set_diagnostics_collection(send_diagnostics = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Workspace\n",
    "Initialize a workspace object from persisted configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Workspace\n",
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print(\"Resource group: \", ws.resource_group)\n",
    "print(\"Location: \", ws.location)\n",
    "print(\"Workspace name: \", ws.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create An Experiment\n",
    "**Experiment** is a logical container in an Azure ML Workspace. It hosts run records which can include run metrics and output artifacts from your experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "experiment_name = 'image-retraining'\n",
    "experiment = Experiment(workspace = ws, name = experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Provision the AKS Cluster\n",
    "\n",
    "We need this cluster later in this exercise to deploy our service.\n",
    "\n",
    "This is a one time setup. You can reuse this cluster for multiple deployments after it has been created. If you delete the cluster or the resource group that contains it, then you would have to recreate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.compute import AksCompute, ComputeTarget\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "aks_name = 'myaks'\n",
    "\n",
    "try:\n",
    "    aks_target = AksCompute(workspace=ws, name=aks_name)\n",
    "    print('found existing:', aks_target.name)\n",
    "except ComputeTargetException:\n",
    "    print('creating new.')\n",
    "\n",
    "    # AKS configuration\n",
    "    prov_config = AksCompute.provisioning_configuration(\n",
    "        agent_count=3,\n",
    "        vm_size=\"Standard_B4ms\"\n",
    "    )\n",
    "    \n",
    "    # Create the cluster\n",
    "    aks_target = ComputeTarget.create(\n",
    "        workspace = ws, \n",
    "        name = aks_name, \n",
    "        provisioning_configuration = prov_config\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Azure ML Compute cluster (GPU-enabled) as a compute target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.compute import AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "compute_target_name = 'myamlcompute'\n",
    "\n",
    "try:\n",
    "    aml_compute = AmlCompute(workspace=ws, name=compute_target_name)\n",
    "    print('found existing:', aml_compute.name)\n",
    "except ComputeTargetException:\n",
    "    print('creating new.')\n",
    "    aml_config = AmlCompute.provisioning_configuration(\n",
    "        vm_size=\"Standard_NC6\",\n",
    "        vm_priority=\"dedicated\",\n",
    "        min_nodes = 0,\n",
    "        max_nodes = 4,\n",
    "        idle_seconds_before_scaledown=300\n",
    "    )\n",
    "    aml_compute = AmlCompute.create(\n",
    "        ws, \n",
    "        name=compute_target_name, \n",
    "        provisioning_configuration=aml_config\n",
    "    )\n",
    "    aml_compute.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload data files into datastore\n",
    "Every workspace comes with a default datastore (and you can register more) which is backed by the Azure blob storage account associated with the workspace. We can use it to transfer data from local to the cloud, and access it from the compute target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default datastore\n",
    "ds = ws.get_default_datastore()\n",
    "print(\"Datastore name: \", ds.name)\n",
    "print(\"Datastore type: \", ds.datastore_type)\n",
    "print(\"Account name: \", ds.account_name)\n",
    "print(\"Container name: \", ds.container_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download and unpack flower images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import urllib.request\n",
    "\n",
    "tmp_path = '../tmp/image_retraining'\n",
    "os.makedirs(tmp_path, exist_ok=True)\n",
    "\n",
    "print('Downloading flower photos...')\n",
    "urllib.request.urlretrieve(\"http://download.tensorflow.org/example_images/flower_photos.tgz\", tmp_path + \"/flower_photos.tgz\")\n",
    "print('Unpacking archive...')\n",
    "shutil.unpack_archive(tmp_path + '/flower_photos.tgz', tmp_path)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload files to the datastore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path = tmp_path + '/flower_photos/'\n",
    "for (dirpath, dirnames, filenames) in os.walk(images_path):\n",
    "    print('Uploading', dirpath, '...')\n",
    "    ds.upload_files(\n",
    "        [dirpath + '/' + f for f in filenames], \n",
    "        target_path=dirpath.replace(tmp_path + '/', ''), \n",
    "        overwrite=True\n",
    "    )\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a project directory\n",
    "Create a directory that will contain all the necessary code from your local machine that you will need access to on the remote resource. This includes the training script, and any additional files your training script depends on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "project_folder = '../projects/image_retraining'\n",
    "os.makedirs(project_folder, exist_ok=True)\n",
    "\n",
    "shutil.copy('./scripts/retrain.py', project_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a TensorFlow estimator\n",
    "The AML SDK's TensorFlow estimator enables you to easily submit TensorFlow training jobs for both single-node and distributed runs. For more information on the TensorFlow estimator, refer [here](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-train-tensorflow)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.dnn import TensorFlow\n",
    "from azureml.core.runconfig import DataReferenceConfiguration\n",
    "\n",
    "script_params={\n",
    "    '--image_dir': str(ds.as_download()),\n",
    "    '--summaries_dir': './logs',\n",
    "    '--output_graph': './outputs/output_graph.pb',\n",
    "    '--output_labels': './outputs/output_labels.txt',\n",
    "    '--saved_model_dir': './outputs/model'\n",
    "}\n",
    "\n",
    "estimator = TensorFlow(source_directory=project_folder,\n",
    "                       source_directory_data_store=ds,\n",
    "                       compute_target=aml_compute,\n",
    "                       script_params=script_params,\n",
    "                       entry_script='retrain.py',\n",
    "                       pip_packages=['tensorflow_hub'],\n",
    "                       node_count=1,\n",
    "                       use_gpu=True)\n",
    "\n",
    "# Overwrite data store reference\n",
    "dr = DataReferenceConfiguration(\n",
    "    datastore_name=ds.name, \n",
    "    path_on_datastore='flower_photos', \n",
    "    mode='download', # download files from datastore to compute target\n",
    "    overwrite=True\n",
    ")\n",
    "estimator.run_config.data_references[ds.name] = dr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit job\n",
    "Run your experiment by submitting your estimator object. Note that this call is asynchronous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = experiment.submit(estimator)\n",
    "print(run.get_details())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "status = run.get_status()\n",
    "seconds = 10\n",
    "while status != 'Completed' and status != 'Failed':\n",
    "    print('current status: {} - waiting...'.format(status))\n",
    "    time.sleep(seconds)\n",
    "    if seconds < 60:\n",
    "        seconds = seconds + 10\n",
    "    status = run.get_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "outputs_path = '../outputs/image_retraining'\n",
    "os.makedirs(outputs_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in run.get_file_names():\n",
    "    if filename.startswith('outputs'):\n",
    "        print(\"downloading\", filename, '...')\n",
    "        run.download_file(\n",
    "            filename, \n",
    "            output_file_path=outputs_path + filename.replace('outputs/','/')\n",
    "        )\n",
    "print('completed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test model locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "print(\"TensorFlow Version: \", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = os.path.join(outputs_path, \"output_graph.pb\")\n",
    "label_file = os.path.join(outputs_path, \"output_labels.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_graph(model_file):\n",
    "    graph = tf.Graph()\n",
    "    graph_def = tf.GraphDef()\n",
    "\n",
    "    with open(model_file, \"rb\") as f:\n",
    "        graph_def.ParseFromString(f.read())\n",
    "    with graph.as_default():\n",
    "        tf.import_graph_def(graph_def)\n",
    "\n",
    "    return graph\n",
    "\n",
    "def read_tensor_from_image_file(file_name,\n",
    "                                input_height=299,\n",
    "                                input_width=299,\n",
    "                                input_mean=0,\n",
    "                                input_std=255):\n",
    "    input_name = \"file_reader\"\n",
    "    output_name = \"normalized\"\n",
    "    file_reader = tf.read_file(file_name, input_name)\n",
    "    if file_name.endswith(\".png\"):\n",
    "        image_reader = tf.image.decode_png(file_reader, channels=3, name=\"png_reader\")\n",
    "    elif file_name.endswith(\".gif\"):\n",
    "        image_reader = tf.squeeze(tf.image.decode_gif(file_reader, name=\"gif_reader\"))\n",
    "    elif file_name.endswith(\".bmp\"):\n",
    "        image_reader = tf.image.decode_bmp(file_reader, name=\"bmp_reader\")\n",
    "    else:\n",
    "        image_reader = tf.image.decode_jpeg(file_reader, channels=3, name=\"jpeg_reader\")\n",
    "    float_caster = tf.cast(image_reader, tf.float32)\n",
    "    dims_expander = tf.expand_dims(float_caster, 0)\n",
    "    resized = tf.image.resize_bilinear(dims_expander, [input_height, input_width])\n",
    "    normalized = tf.divide(tf.subtract(resized, [input_mean]), [input_std])\n",
    "    with tf.Session() as sess:\n",
    "        result = sess.run(normalized)\n",
    "        return result\n",
    "\n",
    "def load_labels(label_file):\n",
    "    label = []\n",
    "    proto_as_ascii_lines = tf.gfile.GFile(label_file).readlines()\n",
    "    for l in proto_as_ascii_lines:\n",
    "        label.append(l.rstrip())\n",
    "    return label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = load_graph(model_file)\n",
    "\n",
    "input_height = 299\n",
    "input_width = 299\n",
    "input_mean = 0\n",
    "input_std = 255\n",
    "\n",
    "input_layer = \"Placeholder\"\n",
    "output_layer = \"final_result\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_flower(data):\n",
    "    input_name = \"import/\" + input_layer\n",
    "    output_name = \"import/\" + output_layer\n",
    "    input_operation = graph.get_operation_by_name(input_name)\n",
    "    output_operation = graph.get_operation_by_name(output_name)\n",
    "\n",
    "    with tf.Session(graph=graph) as sess:\n",
    "        results = sess.run(output_operation.outputs[0], {\n",
    "            input_operation.outputs[0]: data\n",
    "        })\n",
    "    results = np.squeeze(results)\n",
    "\n",
    "    top_k = results.argsort()[-5:][::-1]\n",
    "    labels = load_labels(label_file)\n",
    "    for i in top_k:\n",
    "        print(labels[i], results[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict test data\n",
    "\n",
    "Feed the test dataset to the model to get predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"./resources/test-images/Daisy1.jpg\"\n",
    "\n",
    "t = read_tensor_from_image_file(\n",
    "    file_name,\n",
    "    input_height=input_height,\n",
    "    input_width=input_width,\n",
    "    input_mean=input_mean,\n",
    "    input_std=input_std\n",
    ")\n",
    "\n",
    "predict_flower(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"./resources/test-images/Rose1.jpg\"\n",
    "\n",
    "t = read_tensor_from_image_file(\n",
    "    file_name,\n",
    "    input_height=input_height,\n",
    "    input_width=input_width,\n",
    "    input_mean=input_mean,\n",
    "    input_std=input_std\n",
    ")\n",
    "\n",
    "predict_flower(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy a model in Azure Kubernetes Services (AKS)\n",
    "### Register a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.model import Model\n",
    "\n",
    "model_graph_name = \"flower_photos_graph\"\n",
    "model_labels_name = \"flower_photos_labels\"\n",
    "\n",
    "model_graph = Model.register(\n",
    "    model_path=model_file,\n",
    "    model_name=model_graph_name,\n",
    "    tags={\"data\": \"flower_photos\", \"model\": \"classification\"},\n",
    "    description=\"Retrained Inception V3 model with flower photos\",\n",
    "    workspace=ws\n",
    ")\n",
    "\n",
    "model_labels = Model.register(\n",
    "    model_path=label_file,\n",
    "    model_name=model_labels_name,\n",
    "    tags={\"data\": \"flower_photos\", \"model\": \"classification\"},\n",
    "    description=\"Output labels of the retrained Inception V3 model with flower photos\",\n",
    "    workspace=ws\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy as web service\n",
    "\n",
    "Once you've tested the model and are satisfied with the results, deploy the model as a web service hosted in ACI. \n",
    "\n",
    "To build the correct environment for ACI, provide the following:\n",
    "* A scoring script to show how to use the model\n",
    "* An environment file to show what packages need to be installed\n",
    "* A configuration file to build the ACI\n",
    "* The model you trained before\n",
    "\n",
    "### Check AKS Cluster state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "status = aks_target.get_status()\n",
    "while status != 'Succeeded' and status != 'Failed':\n",
    "    print('current status: {} - waiting...'.format(status))\n",
    "    time.sleep(10)\n",
    "    status = aks_target.get_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create scoring script\n",
    "\n",
    "Create the scoring script, called score.py, used by the web service call to show how to use the model.\n",
    "\n",
    "You must include two required functions into the scoring script:\n",
    "* The `init()` function, which typically loads the model into a global object. This function is run only once when the Docker container is started. \n",
    "\n",
    "* The `run(input_data)` function uses the model to predict a value based on the input data. Inputs and outputs to the run typically use JSON for serialization and de-serialization, but other formats are supported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile score_flowers.py\n",
    "import json\n",
    "import os\n",
    "import traceback\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "from azureml.core.model import Model\n",
    "\n",
    "def load_graph(graph_path):\n",
    "    global graph\n",
    "    global input_operation\n",
    "    global output_operation\n",
    "\n",
    "    print(\"loading graph from\", graph_path, time.strftime(\"%H:%M:%S\"))\n",
    "    graph = tf.Graph()\n",
    "    graph_def = tf.GraphDef()\n",
    "\n",
    "    with open(graph_path, \"rb\") as f:\n",
    "        graph_def.ParseFromString(f.read())\n",
    "\n",
    "    with graph.as_default():\n",
    "        tf.import_graph_def(graph_def)\n",
    "\n",
    "    input_operation = graph.get_operation_by_name('import/Placeholder')\n",
    "    output_operation = graph.get_operation_by_name('import/final_result')\n",
    "    print(\"graph loaded successfully.\", time.strftime(\"%H:%M:%S\"))\n",
    "\n",
    "def load_labels(label_path):\n",
    "    global labels\n",
    "    \n",
    "    print(\"loading labels from\", label_path, time.strftime(\"%H:%M:%S\"))\n",
    "    labels = []\n",
    "    proto_as_ascii_lines = tf.gfile.GFile(label_path).readlines()\n",
    "    for l in proto_as_ascii_lines:\n",
    "        labels.append(l.rstrip())\n",
    "    print(\"labels loaded successfully.\", time.strftime(\"%H:%M:%S\"))\n",
    "\n",
    "def init():\n",
    "    try:\n",
    "        print (\"model initializing\" + time.strftime(\"%H:%M:%S\"))\n",
    "        # retreive the path to the model file using the model name\n",
    "        graph_path = Model.get_model_path('flower_photos_graph')\n",
    "        load_graph(graph_path)\n",
    "\n",
    "        labels_path = Model.get_model_path('flower_photos_labels')\n",
    "        load_labels(labels_path)\n",
    "        print (\"model initialized\" + time.strftime(\"%H:%M:%S\"))\n",
    "    except Exception as e:\n",
    "        error = str(e)\n",
    "        stacktrace = traceback.format_exc()\n",
    "        print (error + time.strftime(\"%H:%M:%S\"))\n",
    "        print (stacktrace)\n",
    "        raise\n",
    "\n",
    "def run(raw_data):\n",
    "    try:\n",
    "        data = json.loads(raw_data)\n",
    "        data = np.array(data)\n",
    "        print (\"image array: \" + str(data)[:50])\n",
    "        \n",
    "        # make prediction\n",
    "        with tf.Session(graph=graph) as sess:\n",
    "            results = sess.run(output_operation.outputs[0], {\n",
    "                input_operation.outputs[0]: data\n",
    "            })\n",
    "        results = np.squeeze(results)\n",
    "\n",
    "        top_k = results.argsort()[-5:][::-1]\n",
    "\n",
    "        result = []\n",
    "        for i in top_k:\n",
    "            result.append([labels[i], results[i]])\n",
    "        print (\"result: \" + str(result))\n",
    "        \n",
    "        # you can return any data type as long as it is JSON-serializable\n",
    "        return str(result)\n",
    "    except Exception as e:\n",
    "        error = str(e)\n",
    "        stacktrace = traceback.format_exc()\n",
    "        print (error + time.strftime(\"%H:%M:%S\"))\n",
    "        print (stacktrace)\n",
    "        return stacktrace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create environment file\n",
    "\n",
    "Next, create an environment file, called myenv.yml, that specifies all of the script's package dependencies. This file is used to ensure that all of those dependencies are installed in the Docker image. This model needs `tensorflow` and `azureml-sdk`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.conda_dependencies import CondaDependencies \n",
    "\n",
    "myenv = CondaDependencies()\n",
    "myenv.add_tensorflow_conda_package(core_type='cpu')\n",
    "myenv.add_conda_package(\"numpy\")\n",
    "#myenv.add_pip_package(\"azureml-monitoring\")\n",
    "\n",
    "with open(os.path.join(project_folder, \"myenv.yml\"),\"w\") as f:\n",
    "    f.write(myenv.serialize_to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review the content of the `myenv.yml` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(project_folder, \"myenv.yml\"),\"r\") as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create image configuration\n",
    "\n",
    "Define the image configuration using:\n",
    "* The scoring file (`score_flowers.py`)\n",
    "* The environment file (`myenv.yml`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.image import ContainerImage\n",
    "\n",
    "# configure the image\n",
    "image_config = ContainerImage.image_configuration(\n",
    "    execution_script=\"score_flowers.py\", \n",
    "    runtime=\"python\", \n",
    "    conda_file=os.path.join(project_folder, \"myenv.yml\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create configuration file\n",
    "\n",
    "Create a deployment configuration file and specify the number of CPUs and gigabyte of RAM needed for your ACI container. While it depends on your model, the default of 1 core and 1 gigabyte of RAM is usually sufficient for many models. If you feel you need more later, you would have to recreate the image and redeploy the service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import AksWebservice\n",
    "\n",
    "aks_config = AksWebservice.deploy_configuration(\n",
    "    cpu_cores=1, \n",
    "    memory_gb=1, \n",
    "    #collect_model_data=True,\n",
    "    enable_app_insights=True, \n",
    "    tags={\"data\": \"flower_photos\",  \"method\" : \"TensorFlow\"}, \n",
    "    description='Predict flowers with TensorFlow'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating and Deploying the image in AKS\n",
    "Estimated time to complete: **about 5-8 minutes**\n",
    "\n",
    "The following code goes through these steps:\n",
    "\n",
    "1. Create the image and store it in the workspace. \n",
    "1. Send the image to the AKS cluster.\n",
    "1. Start up a container in AKS using the image.\n",
    "1. Get the web service HTTP endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from azureml.core.webservice import Webservice\n",
    "\n",
    "service = Webservice.deploy_from_model(\n",
    "    workspace=ws,\n",
    "    name='flower-photos-svc',\n",
    "    deployment_config=aks_config,\n",
    "    deployment_target=aks_target,\n",
    "    models=[model_graph, model_labels],\n",
    "    image_config=image_config\n",
    ")\n",
    "\n",
    "service.wait_for_deployment(show_output=True)\n",
    "print(service.state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the scoring web service's HTTP endpoint, which accepts REST client calls. This endpoint can be shared with anyone who wants to test the web service or integrate it into an application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(service.scoring_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test deployed service\n",
    "\n",
    "Earlier you scored all the test data with the local version of the model. Now, you can test the deployed model with a random sample of 30 images from the test data.  \n",
    "\n",
    "The following code goes through these steps:\n",
    "1. Send the data as a JSON array to the web service hosted in ACI. \n",
    "\n",
    "1. Use the SDK's `run` API to invoke the service. You can also make raw calls using any HTTP tool such as curl.\n",
    "\n",
    "1. Print the returned predictions and plot them along with the input images. Red font and inverse image (white on black) is used to highlight the misclassified samples. \n",
    "\n",
    " Since the model accuracy is high, you might have to run the following code a few times before you can see a misclassified sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "file_name = \"./resources/test-images/Daisy1.jpg\"\n",
    "#file_name = \"./test.png\"\n",
    "\n",
    "\n",
    "\n",
    "for dirpath, dnames, fnames in os.walk(\"./resources/test-images/\"):\n",
    "    for f in fnames:\n",
    "        file_name = os.path.join(dirpath, f)\n",
    "        \n",
    "        # load image\n",
    "        print(\"Loading image\", file_name)\n",
    "\n",
    "        data = read_tensor_from_image_file(\n",
    "            file_name,\n",
    "            input_height=input_height,\n",
    "            input_width=input_width,\n",
    "            input_mean=input_mean,\n",
    "            input_std=input_std\n",
    "        )\n",
    "        raw_data = str(data.tolist())\n",
    "\n",
    "        # predict using the deployed model\n",
    "        print(\"Sending image\", f, \"to service\")\n",
    "        response = service.run(input_data=raw_data)\n",
    "        print(\"Service response:\", response)\n",
    "        #result = json.loads(response)\n",
    "        #print(\"Predicted class:\", result[0][0])\n",
    "        #print(\"Probability:\", result[0][1])\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also send raw HTTP request to test the web service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "api_keys = service.get_keys()\n",
    "headers = {\n",
    "    'Content-Type':'application/json',\n",
    "    'Authorization':('Bearer '+ api_keys[0])\n",
    "}\n",
    "\n",
    "file_name = \"./resources/test-images/Daisy1.jpg\"\n",
    "\n",
    "data = read_tensor_from_image_file(\n",
    "    file_name,\n",
    "    input_height=input_height,\n",
    "    input_width=input_width,\n",
    "    input_mean=input_mean,\n",
    "    input_std=input_std\n",
    ")\n",
    "input_data = str(data.tolist())\n",
    "\n",
    "print(\"POST to url\", service.scoring_uri)\n",
    "resp = requests.post(service.scoring_uri, input_data, headers=headers)\n",
    "print(\"prediction:\", resp.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up resources\n",
    "\n",
    "To keep the resource group and workspace for other tutorials and exploration, you can delete only the ACI deployment using this API call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service.delete()\n",
    "if os.path.exists('score_flowers.py'):\n",
    "    os.remove('score_flowers.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.contrib.tensorboard import Tensorboard\n",
    "\n",
    "# The Tensorboard constructor takes an array of runs, so be sure and pass it in as a single-element array here\n",
    "tb = Tensorboard([run])\n",
    "\n",
    "# If successful, start() returns a string with the URI of the instance.\n",
    "tb.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop TensorBoard\n",
    "When you're done, make sure to call the stop() method of the Tensorboard object, or it will stay running even after your job completes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
