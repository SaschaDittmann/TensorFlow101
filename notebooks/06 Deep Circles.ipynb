{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Circles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_circles\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions for plotting the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   plot the data on a figure\n",
    "def plot_data(pl, X, y):\n",
    "    # plot class where y==0\n",
    "    pl.plot(X[y==0, 0], X[y==0,1], 'ob', alpha=0.5)\n",
    "    # plot class where y==1\n",
    "    pl.plot(X[y==1, 0], X[y==1,1], 'xr', alpha=0.5)\n",
    "    pl.legend(['0', '1'])\n",
    "    return pl\n",
    "\n",
    "#   Common function that draws the decision boundaries\n",
    "def plot_decision_boundary(model, X, y):\n",
    "\n",
    "    amin, bmin = X.min(axis=0) - 0.1\n",
    "    amax, bmax = X.max(axis=0) + 0.1\n",
    "    hticks = np.linspace(amin, amax, 101)\n",
    "    vticks = np.linspace(bmin, bmax, 101)\n",
    "    \n",
    "    aa, bb = np.meshgrid(hticks, vticks)\n",
    "    ab = np.c_[aa.ravel(), bb.ravel()]\n",
    "    \n",
    "    # make prediction with the model and reshape the output so contourf can plot it\n",
    "    c = model.predict(ab)\n",
    "    Z = c.reshape(aa.shape)\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    # plot the contour\n",
    "    plt.contourf(aa, bb, Z, cmap='bwr', alpha=0.2)\n",
    "    # plot the moons of data\n",
    "    plot_data(plt, X, y)\n",
    "\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Demo Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data will be either 0 or 1 when 2 is number of centers.\n",
    "# X is a [number of samples, 2] sized array. X[sample] contains its x,y position of the sample in the space\n",
    "# ex: X[1] = [1.342, -2.3], X[2] = [-4.342, 2.12]\n",
    "# y is a [number of samples] sized array. y[sample] contains the class index (ie. 0 or 1 when there are 2 centers)\n",
    "# ex: y[1] = 0 , y[1] = 1\n",
    "X, y = make_circles(n_samples=1000, factor=.6, noise=0.1, random_state=58)\n",
    "pl = plot_data(plt, X, y)\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into Training and Test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define & Train Model with only one neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Keras libraries\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Simple Sequential model\n",
    "model = Sequential()\n",
    "#   Add a Dense Fully Connected Layer with 1 neuron.  Using input_shape = (2,) says the input will \n",
    "#       be arrays of the form (*,2).  The first dimension will be an unspecified \n",
    "#       number of batches (rows) of data.  The second dimension is 2 which are the X, Y positions of each data element.\n",
    "#       The sigmoid activation function is used to return 0 or 1, signifying the data \n",
    "#       cluster the position is predicted to belong to.\n",
    "model.add(Dense(1, input_shape=(2,), activation=\"sigmoid\"))\n",
    "#   Compile the model.  Minimize crossentopy for a binary.  Maximize for accuracy\n",
    "model.compile(Adam(lr=0.05), 'binary_crossentropy', metrics=['accuracy'])\n",
    "#   Fit the model with the data from make_blobs.  Make 100 cycles through the data.\n",
    "#       Set verbose to 0 to supress progress messages \n",
    "model.fit(X_train, y_train, epochs=100, verbose=1)\n",
    "#   Get loss and accuracy on test data\n",
    "eval_result = model.evaluate(X_test, y_test)\n",
    "#   Print test accuracy\n",
    "print(\"\\n\\nTest loss:\", eval_result[0], \"Test accuracy:\", eval_result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Plot the decision boundary\n",
    "plot_decision_boundary(model, X, y).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Mulilayer Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the keras model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "#   Simple Sequential model\n",
    "model = Sequential()\n",
    "model.add(Dense(4, input_shape=(2,), activation=\"tanh\", name=\"Hidden-1\"))\n",
    "model.add(Dense(4, activation=\"tanh\", name=\"Hidden-2\"))\n",
    "#   Add a Dense Fully Connected Layer with 1 neuron.  Using input_shape = (2,) says the input will \n",
    "#       be arrays of the form (*,2).  The first dimension will be an unspecified \n",
    "#       number of batches (rows) of data.  The second dimension is 2 which are the X, Y positions of each data element.\n",
    "#       The sigmoid activation function is used to return 0 or 1, signifying the data \n",
    "#       cluster the position is predicted to belong to.\n",
    "model.add(Dense(1, activation=\"sigmoid\", name=\"output_layer\"))\n",
    "model.summary()\n",
    "#   Compile the model.  Minimize crossentopy for a binary.  Maximize for accuracy\n",
    "model.compile(Adam(lr=0.05), 'binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model with early stopping callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Define early stopping callback\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "my_callbacks = [EarlyStopping(monitor='val_accuracy', patience=5, mode='max')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Fit the model with the data from make_blobs.  Make 100 cycles through the data.\n",
    "#       Set verbose to 0 to supress progress messages \n",
    "model.fit(X_train, y_train, epochs=200, verbose=1, callbacks=my_callbacks, validation_data=(X_test, y_test))\n",
    "#   Get loss and accuracy on test data\n",
    "eval_result = model.evaluate(X_test, y_test)\n",
    "#   Print test accuracy\n",
    "print(\"\\n\\nTest loss:\", eval_result[0], \"Test accuracy:\", eval_result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Plot the decision boundary\n",
    "plot_decision_boundary(model, X, y).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
