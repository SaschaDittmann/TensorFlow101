{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fashion MNIST\n",
    "\n",
    "## Validate Azure ML SDK installation and get version number for debugging purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check core SDK version number\n",
    "import azureml.core\n",
    "print(\"SDK version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Workspace\n",
    "Initialize a workspace object from persisted configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Workspace\n",
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print(\"Resource group: \", ws.resource_group)\n",
    "print(\"Location: \", ws.location)\n",
    "print(\"Workspace name: \", ws.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a project directory\n",
    "Create a directory that will contain all the necessary code from your local machine that you will need access to on the remote resource. This includes the training script, and any additional files your training script depends on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "project_folder = '../projects/fashion_mnist_amlcompute'\n",
    "os.makedirs(project_folder, exist_ok=True)\n",
    "\n",
    "shutil.copy('./scripts/train_Fashion_MNIST.py', project_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create An Experiment\n",
    "**Experiment** is a logical container in an Azure ML Workspace. It hosts run records which can include run metrics and output artifacts from your experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "experiment_name = 'fashion-mnist'\n",
    "experiment = Experiment(workspace = ws, name = experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Azure ML Compute cluster (GPU-enabled) as a compute target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.compute import AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "compute_target_name = 'gpu-cluster'\n",
    "\n",
    "try:\n",
    "    aml_compute = AmlCompute(workspace=ws, name=compute_target_name)\n",
    "    print('found existing:', aml_compute.name)\n",
    "except ComputeTargetException:\n",
    "    print('creating new.')\n",
    "    aml_config = AmlCompute.provisioning_configuration(\n",
    "        vm_size=\"Standard_NC6\",\n",
    "        vm_priority=\"dedicated\",\n",
    "        min_nodes = 0,\n",
    "        max_nodes = 4,\n",
    "        idle_seconds_before_scaledown=300\n",
    "    )\n",
    "    aml_compute = AmlCompute.create(\n",
    "        ws, \n",
    "        name=compute_target_name, \n",
    "        provisioning_configuration=aml_config\n",
    "    )\n",
    "    aml_compute.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Training Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from azureml.core.environment import Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "myenv = Environment(name=\"mytfenv\")\n",
    "\n",
    "# Adds dependencies to PythonSection of myenv\n",
    "conda_dep = CondaDependencies()\n",
    "conda_dep.add_conda_package(\"matplotlib=3.3.3\")\n",
    "conda_dep.add_pip_package(\"tensorflow-gpu==2.4.1\")\n",
    "myenv.python.conda_dependencies=conda_dep\n",
    "\n",
    "myenv.register(workspace=ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(conda_dep.serialize_to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# OPTIONAL: Pre-Build Docker Image for Training\n",
    "from azureml.core import Image\n",
    "build = myenv.build(workspace=ws)\n",
    "build.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload Data to Azure\n",
    "1. Download the [Fashion MNIST Dataset](https://github.com/zalandoresearch/fashion-mnist) from GitHub\n",
    "1. Upload the files to the Azure ML Default DataStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "\n",
    "data_folder = '../data/fashion_mnist'\n",
    "os.makedirs(data_folder, exist_ok = True)\n",
    "urllib.request.urlretrieve('https://github.com/zalandoresearch/fashion-mnist/raw/master/data/fashion/train-images-idx3-ubyte.gz', filename=os.path.join(data_folder, \"train-images.gz\"))\n",
    "urllib.request.urlretrieve('https://github.com/zalandoresearch/fashion-mnist/raw/master/data/fashion/train-labels-idx1-ubyte.gz', filename=os.path.join(data_folder, \"train-labels.gz\"))\n",
    "urllib.request.urlretrieve('https://github.com/zalandoresearch/fashion-mnist/raw/master/data/fashion/t10k-images-idx3-ubyte.gz', filename=os.path.join(data_folder, \"test-images.gz\"))\n",
    "urllib.request.urlretrieve('https://github.com/zalandoresearch/fashion-mnist/raw/master/data/fashion/t10k-labels-idx1-ubyte.gz', filename=os.path.join(data_folder, \"test-labels.gz\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ws.get_default_datastore()\n",
    "\n",
    "print(\"Datastore details:\")\n",
    "print(\"Type:\", ds.datastore_type)\n",
    "print(\"Storage Account:\", ds.account_name)\n",
    "print(\"Blob Container Name:\", ds.container_name)\n",
    "\n",
    "ds.upload(src_dir=data_folder, target_path='fashion_mnist', overwrite=True, show_progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit the Experiment\n",
    "Finally, run the training job on Azure ML Compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import ScriptRunConfig\n",
    "\n",
    "script_params = [ '--data-folder', str(ds.as_mount()), '--batch-size', 128, '--epochs', 24]\n",
    "\n",
    "# Training Script and Parameters are used in the estimator to run an experiment\n",
    "runconfig = ScriptRunConfig(source_directory=project_folder,\n",
    "                            compute_target=aml_compute,\n",
    "                            environment=myenv,\n",
    "                            script='train_Fashion_MNIST.py',\n",
    "                            arguments=script_params)\n",
    "\n",
    "runconfig.run_config.data_references = {\n",
    "    ds.as_mount().data_reference_name: ds.as_mount().to_config()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = experiment.submit(runconfig)\n",
    "run.tag(\"Description\",\"AML Compute trained Fashion MNIST model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show Metrics & Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all metris logged in the run\n",
    "run.get_metrics()\n",
    "metrics = run.get_metrics()\n",
    "\n",
    "import numpy as np\n",
    "print('loss is {0:.2f}, and accuracy is {1:0.2f}'.format(\n",
    "    metrics['loss'], \n",
    "    metrics['accuracy']\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot data to see relationships in training and validation data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "epoch_list = list(range(1, len(metrics['Training Accuracy']) + 1))  # values for x axis [1, 2, ..., # of epochs]\n",
    "plt.plot(epoch_list, metrics['Training Accuracy'], epoch_list, metrics['Validation Accuracy'])\n",
    "plt.legend(('Training Accuracy', 'Validation Accuracy'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show all the files stored within the run record\n",
    "run.get_file_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = run.register_model(\n",
    "    model_name='fashion-mnist-model', \n",
    "    model_path='outputs/keras/full_model.h5',\n",
    "    tags={\"data\": \"fashion-mnist\", \"model\": \"classification\"},\n",
    "    description=\"Fashion MNIST image recognition\"\n",
    ")\n",
    "\n",
    "print(\"Model name: \", model.name)\n",
    "print(\"Model id: \", model.id)\n",
    "print(\"Model version: \", model.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "outputs_path = os.path.join(project_folder, \"outputs\")\n",
    "os.makedirs(outputs_path, exist_ok=True)\n",
    "\n",
    "for filename in run.get_file_names():\n",
    "    if filename.startswith('outputs'):\n",
    "        path = os.path.join(project_folder, filename)\n",
    "        print(\"Downloading \" + filename)\n",
    "        run.download_file(filename, output_file_path=outputs_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
